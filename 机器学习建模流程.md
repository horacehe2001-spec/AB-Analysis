# 机器学习建模流程

## 1. 明确问题

在建模之前，首先需要明确业务目标和建模类型：

- **回归问题**：预测连续数值（如产品尺寸、良率、强度等）
- **分类问题**：预测离散类别（如合格/不合格、故障类型等）

确定目标变量 Y（输出）和候选特征变量 X（输入），并明确模型的应用场景和期望精度。

---

## 2. 数据收集与整合

从各类数据源采集建模所需的数据：

- 数据库（MES、ERP、SCADA 等）
- 传感器实时数据
- 人工记录（Excel、纸质表单等）
- 实验数据（DOE 结果）

最终汇总为结构化表格：

- 每行代表一个样本（一次生产、一次测量等）
- 每列代表一个特征变量（X）或目标变量（Y）

---

## 3. 数据探索（EDA）

在建模之前，对数据进行全面的探索性分析：

### 3.1 数据概览

- 样本量、特征数量
- 各变量的数据类型（连续型、类别型）
- 缺失值统计
- 基本统计量（均值、标准差、最大值、最小值、分位数）

### 3.2 分布分析

- 直方图：查看各变量的分布形态
- 箱线图：识别离群值和数据集中趋势
- 正态性检验：判断数据是否服从正态分布

### 3.3 相关性分析

- 散点图矩阵：观察变量间的关系
- 相关系数矩阵（Pearson / Spearman）：量化线性/单调相关性
- 热力图：直观展示变量间的关联强度

### 3.4 异常检测

- 识别明显的离群点和异常记录
- 判断异常数据是真实波动还是采集错误

---

## 4. 数据预处理

### 4.1 缺失值处理

| 方法 | 适用场景 |
|------|---------|
| 删除 | 缺失比例低（<5%），且样本量充足 |
| 均值/中位数填充 | 缺失随机分布，对结果影响小 |
| 插值法 | 时间序列数据，相邻数据有关联 |
| 模型预测填充 | 缺失比例较高，其他特征可预测该值 |

### 4.2 异常值处理

| 方法 | 说明 |
|------|------|
| 3σ 原则 | 超出均值 ± 3 倍标准差的数据视为异常 |
| IQR 方法 | 超出 Q1 - 1.5×IQR 或 Q3 + 1.5×IQR 的数据视为异常 |
| 业务判断 | 结合工艺知识判断是否为合理数据 |

处理方式：剔除、截断（Winsorize）或保留（如果确认为真实波动）。

### 4.3 数据标准化/归一化

| 方法 | 公式 | 适用场景 |
|------|------|---------|
| Z-score 标准化 | (X - μ) / σ | 大多数算法，尤其是对距离敏感的算法 |
| Min-Max 归一化 | (X - Xmin) / (Xmax - Xmin) | 需要将数据映射到固定范围（如 0-1） |

注意：树模型（随机森林、XGBoost）对量纲不敏感，可不做标准化。

### 4.4 类别变量编码

| 方法 | 适用场景 |
|------|---------|
| One-Hot 编码 | 类别无序（如设备编号、班次） |
| Label 编码 | 类别有序（如低/中/高） |
| Target 编码 | 类别数量多，One-Hot 维度爆炸时 |

### 4.5 多重共线性检查

- 计算方差膨胀因子（VIF），VIF > 10 表示严重共线性
- 处理方法：剔除冗余变量、PCA 降维、使用正则化模型

---

## 5. 特征工程

### 5.1 特征选择

从已有特征中筛选出对 Y 最有贡献的特征：

| 方法 | 说明 |
|------|------|
| 过滤法 | 相关系数筛选、方差筛选、卡方检验 |
| 包裹法 | 递归特征消除（RFE），逐步回归 |
| 嵌入法 | Lasso 回归（L1 正则化）、树模型特征重要性排序 |

### 5.2 特征构造

基于业务知识和数据分析结果，创造新的特征变量：

- 比值特征：X₁ / X₂
- 交互特征：X₁ × X₂
- 多项式特征：X₁²、X₂²
- 时间窗口统计：滑动平均、滑动标准差
- 分箱/离散化：将连续变量转为区间类别

---

## 6. 数据集划分

将数据划分为训练集、验证集和测试集：

| 数据集 | 比例 | 用途 |
|--------|------|------|
| 训练集 | 70-80% | 训练模型，拟合参数 |
| 验证集 | 10-15% | 调整超参数，选择最优模型 |
| 测试集 | 10-15% | 最终评估模型性能，仅使用一次 |

**注意事项**：

- 时间序列数据应按时间顺序划分，不可随机打乱
- 小数据集（< 1000 条）推荐使用 K 折交叉验证（K=5 或 10）
- 确保各数据集的 Y 分布一致（分层抽样）

---

## 7. 模型选择与训练

### 7.1 候选模型

建议从简单到复杂逐步尝试：

| 模型 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| 多元线性回归 | 可解释性强，计算快 | 只能拟合线性关系 | 基线模型，变量关系简单 |
| 岭回归 / Lasso | 处理共线性，防过拟合 | 仍为线性模型 | 特征多、共线性严重 |
| 决策树 | 直观易懂，无需标准化 | 容易过拟合 | 快速原型，规则提取 |
| 随机森林 | 精度高，不易过拟合 | 可解释性一般 | 通用场景，中等数据量 |
| XGBoost / LightGBM | 精度高，速度快 | 需要调参 | 结构化数据的首选 |
| 支持向量机（SVR/SVC） | 小样本表现好 | 大数据集训练慢 | 小样本、高维数据 |
| 神经网络 | 拟合复杂非线性关系 | 需大量数据，黑箱 | 数据量大，关系极复杂 |

### 7.2 工业场景推荐策略

1. 先用**多元线性回归**建立基线，确认基本关系
2. 再用**随机森林或 XGBoost**提升精度
3. 仅在数据量充足且需求明确时考虑**神经网络**

### 7.3 训练过程

- 使用训练集拟合模型参数
- 记录训练过程中的损失函数变化
- 观察是否收敛

---

## 8. 模型评估

### 8.1 回归问题评估指标

| 指标 | 公式 | 说明 |
|------|------|------|
| R²（决定系数） | 1 - SS_res / SS_tot | 模型解释的变异比例，越接近 1 越好 |
| RMSE（均方根误差） | √(Σ(y - ŷ)² / n) | 预测误差的标准差，越小越好 |
| MAE（平均绝对误差） | Σ\|y - ŷ\| / n | 平均预测偏差，越小越好 |
| MAPE（平均百分比误差） | Σ\|y - ŷ\| / y / n × 100% | 相对误差百分比，越小越好 |

### 8.2 分类问题评估指标

| 指标 | 说明 |
|------|------|
| 准确率（Accuracy） | 整体预测正确的比例 |
| 精确率（Precision） | 预测为正类中真正为正类的比例 |
| 召回率（Recall） | 实际正类中被正确识别的比例 |
| F1 Score | 精确率与召回率的调和平均 |
| AUC-ROC | 综合衡量分类器在各阈值下的表现 |
| 混淆矩阵 | 详细展示各类别的预测结果分布 |

### 8.3 过拟合与欠拟合判断

| 现象 | 训练集表现 | 测试集表现 | 诊断 | 对策 |
|------|-----------|-----------|------|------|
| 过拟合 | 好 | 差 | 模型过于复杂 | 增加数据、正则化、减少特征、简化模型 |
| 欠拟合 | 差 | 差 | 模型过于简单 | 增加特征、使用更复杂模型、减少正则化 |
| 理想状态 | 好 | 好 | 泛化能力强 | 保持当前模型 |

---

## 9. 超参数调优

### 9.1 常用调参方法

| 方法 | 说明 | 适用场景 |
|------|------|---------|
| 网格搜索（Grid Search） | 穷举所有参数组合 | 参数少、搜索空间小 |
| 随机搜索（Random Search） | 随机采样参数组合 | 参数多、搜索空间大 |
| 贝叶斯优化（Bayesian Optimization） | 基于历史结果智能搜索 | 训练成本高、需高效搜索 |

### 9.2 关键超参数示例

**随机森林**：

- n_estimators：树的数量
- max_depth：树的最大深度
- min_samples_split：节点分裂最小样本数

**XGBoost**：

- learning_rate：学习率
- max_depth：树的最大深度
- n_estimators：迭代次数
- subsample：样本采样比例
- colsample_bytree：特征采样比例

### 9.3 调参原则

- 使用交叉验证评估每组参数的表现
- 先粗调（大范围），再细调（小范围）
- 关注验证集表现，避免在训练集上过度优化

---

## 10. 模型验证

### 10.1 测试集最终评估

- 用从未参与训练和调参的测试集进行最终评估
- 对比训练集与测试集的指标差异，确认无过拟合

### 10.2 残差分析（回归问题）

- 残差应随机分布，无明显模式
- 残差应近似正态分布
- 残差与预测值之间不应存在系统性关系

### 10.3 业务验证

- 模型结论是否符合工艺经验和物理规律
- 特征重要性排序是否合理
- 在极端工况下模型预测是否可靠

---

## 11. 模型部署与监控

### 11.1 模型保存与部署

- 将训练好的模型序列化保存（如 pickle、joblib、ONNX 格式）
- 部署到生产环境（API 服务、嵌入式系统、边缘计算等）
- 建立输入数据校验机制，确保输入格式和范围正确

### 11.2 持续监控

| 监控内容 | 方法 | 触发条件 |
|---------|------|---------|
| 预测精度 | 定期对比预测值与实际值 | 精度下降超过阈值 |
| 数据漂移 | 监控输入特征分布变化 | 分布偏移显著 |
| 概念漂移 | 监控 Y 与 X 关系变化 | 模型残差增大 |

### 11.3 模型更新策略

- **定期重训练**：按固定周期（如每月）用最新数据重新训练
- **触发式重训练**：当监控指标超出阈值时自动触发重训练
- **增量学习**：在原模型基础上用新数据更新（适用于部分算法）

---

## 总结

```
明确问题 → 数据收集 → 数据探索 → 数据预处理 → 特征工程
    → 数据集划分 → 模型训练 → 模型评估 → 超参数调优
    → 模型验证 → 部署与监控
```

整个流程并非单向线性，而是不断迭代优化的过程。在实际项目中，往往需要多次回到前面的步骤调整数据处理方式或特征工程策略，以获得更优的模型效果。
